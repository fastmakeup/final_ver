"""
ê³µê³µê¸°ê´€/ê³µê¸°ì—… ì¸ìˆ˜ì¸ê³„ RAG ì‹œìŠ¤í…œ v2
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë²¡í„°)
- ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
- êµ¬ì¡°í™”ëœ ì‘ë‹µ
"""

import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI
import os
import glob
import re
from typing import List, Dict, Tuple
from collections import Counter

# BM25 ê²€ìƒ‰ìš©
from rank_bm25 import BM25Okapi
import numpy as np

# íŒŒì¼ ì½ê¸°
from pypdf import PdfReader
from docx import Document
import pandas as pd
import olefile
import zlib
import zipfile
import xml.etree.ElementTree as ET

# ============== ì„¤ì • ==============
BASE_URL = "http://localhost:8000/v1"
API_KEY = "EMPTY"
MODEL_NAME = "mistralai/Mistral-Nemo-Instruct-2407"

CHROMA_DB_PATH = "./chroma_db_handover"
DATA_DIR = "./my_data"
# =================================


class QueryClassifier:
    """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ê¸°"""
    
    QUERY_TYPES = {
        "budget": ["ì˜ˆì‚°", "ê¸ˆì•¡", "ë¹„ìš©", "ì›", "ì²œì›", "ë§Œì›", "ì–µ", "ê²°ì‚°", "ì„¸ì¶œ", "ì„¸ì…", "ì‚°ì¶œ"],
        "regulation": ["ê·œì •", "ì§€ì¹¨", "ë§¤ë‰´ì–¼", "ì ˆì°¨", "ë°©ë²•", "ê¸°ì¤€", "ì¡°í•­", "ë²•ë ¹", "ê·œì¹™"],
        "organization": ["ë‹´ë‹¹ì", "ë¶€ì„œ", "ì¡°ì§", "íŒ€", "ê³¼", "ì‹¤", "ë³¸ë¶€", "ì„¼í„°", "ë‹´ë‹¹"],
        "history": ["ì—°í˜", "ë³€ê²½", "ì´ë ¥", "ê°œì •", "ìˆ˜ì •", "ì–¸ì œ", "ë…„ë„", "ì›”", "ì¼ì"],
        "process": ["ì—…ë¬´", "í”„ë¡œì„¸ìŠ¤", "ì§„í–‰", "ìˆœì„œ", "ë‹¨ê³„", "íë¦„", "ì²˜ë¦¬", "ë°©ì‹"]
    }
    
    @classmethod
    def classify(cls, query: str) -> Tuple[str, float]:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ ë° ì‹ ë¢°ë„ ë°˜í™˜"""
        scores = {}
        
        for qtype, keywords in cls.QUERY_TYPES.items():
            score = sum(1 for kw in keywords if kw in query)
            scores[qtype] = score
        
        if max(scores.values()) == 0:
            return "general", 0.0
        
        best_type = max(scores, key=scores.get)
        confidence = scores[best_type] / len(cls.QUERY_TYPES[best_type])
        
        return best_type, min(confidence, 1.0)


class HybridSearcher:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ (BM25 + ë²¡í„°)"""
    
    def __init__(self, collection):
        self.collection = collection
        self.documents = []
        self.doc_ids = []
        self.bm25 = None
        self._build_bm25_index()
    
    def _tokenize(self, text: str) -> List[str]:
        """í•œêµ­ì–´ í† í¬ë‚˜ì´ì§• (ê°„ë‹¨ ë²„ì „)"""
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°± ë¶„ë¦¬
        text = re.sub(r'[^\w\s]', ' ', text)
        tokens = text.split()
        return [t for t in tokens if len(t) > 1]
    
    def _build_bm25_index(self):
        """BM25 ì¸ë±ìŠ¤ êµ¬ì¶•"""
        # ChromaDBì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        all_docs = self.collection.get(include=["documents", "metadatas"])
        
        if not all_docs['documents']:
            return
        
        self.documents = all_docs['documents']
        self.doc_ids = all_docs['ids']
        self.metadatas = all_docs['metadatas']
        
        # í† í¬ë‚˜ì´ì§•
        tokenized_docs = [self._tokenize(doc) for doc in self.documents]
        
        # BM25 ì¸ë±ìŠ¤ ìƒì„±
        self.bm25 = BM25Okapi(tokenized_docs)
        print(f"   ğŸ“Š BM25 ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(self.documents)}ê°œ ë¬¸ì„œ")
    
    def search(self, query: str, n_results: int = 5, 
               bm25_weight: float = 0.3, vector_weight: float = 0.7) -> Dict:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰"""
        
        # 1. ë²¡í„° ê²€ìƒ‰
        vector_results = self.collection.query(
            query_texts=[query],
            n_results=n_results * 2  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ ë³‘í•©
        )
        
        # 2. BM25 ê²€ìƒ‰
        bm25_scores = {}
        if self.bm25:
            query_tokens = self._tokenize(query)
            scores = self.bm25.get_scores(query_tokens)
            
            # ìƒìœ„ n_results * 2ê°œ ì„ íƒ
            top_indices = np.argsort(scores)[::-1][:n_results * 2]
            
            for idx in top_indices:
                if scores[idx] > 0:
                    bm25_scores[self.doc_ids[idx]] = scores[idx]
        
        # 3. ì ìˆ˜ ë³‘í•©
        combined_scores = {}
        
        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì ìˆ˜í™” (ê±°ë¦¬ ê¸°ë°˜)
        for i, doc_id in enumerate(vector_results['ids'][0]):
            # ChromaDBëŠ” ê±°ë¦¬ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ì—­ìˆ˜ë¡œ ë³€í™˜
            distance = vector_results['distances'][0][i] if 'distances' in vector_results else 0
            vector_score = 1 / (1 + distance)  # ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            combined_scores[doc_id] = vector_score * vector_weight
        
        # BM25 ì ìˆ˜ ì¶”ê°€
        if bm25_scores:
            max_bm25 = max(bm25_scores.values())
            for doc_id, score in bm25_scores.items():
                normalized_score = score / max_bm25 if max_bm25 > 0 else 0
                if doc_id in combined_scores:
                    combined_scores[doc_id] += normalized_score * bm25_weight
                else:
                    combined_scores[doc_id] = normalized_score * bm25_weight
        
        # 4. ìƒìœ„ n_results ì„ íƒ
        sorted_ids = sorted(combined_scores.keys(), 
                           key=lambda x: combined_scores[x], 
                           reverse=True)[:n_results]
        
        # 5. ê²°ê³¼ êµ¬ì„±
        result_docs = []
        result_metas = []
        
        for doc_id in sorted_ids:
            idx = self.doc_ids.index(doc_id)
            result_docs.append(self.documents[idx])
            result_metas.append(self.metadatas[idx])
        
        return {
            'documents': [result_docs],
            'metadatas': [result_metas],
            'ids': [sorted_ids]
        }


class HandoverRAG:
    """ê³µê³µê¸°ê´€ ì¸ìˆ˜ì¸ê³„ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.client = OpenAI(base_url=BASE_URL, api_key=API_KEY)
        self.collection = None
        self.searcher = None
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompts = {
            "budget": """ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì˜ˆì‚°/íšŒê³„ ì „ë¬¸ ì¸ìˆ˜ì¸ê³„ ë‹´ë‹¹ìì…ë‹ˆë‹¤.

[í•µì‹¬ ì§€ì¹¨]
1. ì˜ˆì‚° ê¸ˆì•¡ì€ ì²œ ë‹¨ìœ„ ì‰¼í‘œ í¬í•¨, 1ì› ë‹¨ìœ„ê¹Œì§€ ì •í™•íˆ (ì˜ˆ: 20,377,728ì›)
2. í‘œ í˜•ì‹ìœ¼ë¡œ í•­ëª©-ì‚°ì¶œì‹-ê¸ˆì•¡ì„ ëª…í™•íˆ ì •ë¦¬
3. ì„¸ë¶€ í•­ëª© í•©ê³„ì™€ ì´ê³„ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì‚°í•˜ì—¬ í‘œì‹œ
4. ì˜ˆì‚° í¸ì„± ê·¼ê±°ì™€ ê´€ë ¨ ê·œì •ì„ í•¨ê»˜ ì•ˆë‚´
5. ì „ë…„ ëŒ€ë¹„ ì¦ê°ì´ ìˆë‹¤ë©´ ë³€ë™ ì‚¬ìœ  ì„¤ëª…""",

            "regulation": """ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ê·œì •/ì§€ì¹¨ ì „ë¬¸ ì¸ìˆ˜ì¸ê³„ ë‹´ë‹¹ìì…ë‹ˆë‹¤.

[í•µì‹¬ ì§€ì¹¨]
1. ê·œì •ì˜ ì¡°í•­ ë²ˆí˜¸ì™€ ì •í™•í•œ ë¬¸êµ¬ë¥¼ ì¸ìš©
2. ì ìš© ëŒ€ìƒê³¼ ì˜ˆì™¸ ì‚¬í•­ì„ ëª…í™•íˆ êµ¬ë¶„
3. ê´€ë ¨ëœ ìƒìœ„ ë²•ë ¹ì´ë‚˜ ë‹¤ë¥¸ ê·œì • ì–¸ê¸‰
4. ì‹¤ë¬´ ì ìš© ì‹œ ì£¼ì˜ì‚¬í•­ ì•ˆë‚´
5. ê°œì • ì´ë ¥ì´ ìˆë‹¤ë©´ ìµœì‹  ë²„ì „ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€""",

            "organization": """ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì¡°ì§/ì¸ì‚¬ ì „ë¬¸ ì¸ìˆ˜ì¸ê³„ ë‹´ë‹¹ìì…ë‹ˆë‹¤.

[í•µì‹¬ ì§€ì¹¨]
1. ë‹´ë‹¹ ë¶€ì„œì™€ ë‹´ë‹¹ì ì •ë³´ë¥¼ ì •í™•íˆ ì „ë‹¬
2. ì—…ë¬´ ë¶„ì¥ ë° ê²°ì¬ ë¼ì¸ ì„¤ëª…
3. ìœ ê´€ ë¶€ì„œì™€ì˜ í˜‘ì—… ê´€ê³„ ì•ˆë‚´
4. ë¹„ìƒ ì—°ë½ì²˜ë‚˜ ëŒ€ì²´ ë‹´ë‹¹ì ì •ë³´ í¬í•¨
5. ì¡°ì§ ë³€ê²½ ì´ë ¥ì´ ìˆë‹¤ë©´ í•¨ê»˜ ì„¤ëª…""",

            "history": """ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì—…ë¬´ ì´ë ¥ ê´€ë¦¬ ì „ë¬¸ ì¸ìˆ˜ì¸ê³„ ë‹´ë‹¹ìì…ë‹ˆë‹¤.

[í•µì‹¬ ì§€ì¹¨]
1. ì‹œê°„ìˆœìœ¼ë¡œ ë³€ê²½ ì´ë ¥ ì •ë¦¬ (ìµœì‹ ìˆœ ë˜ëŠ” ê³¼ê±°ìˆœ)
2. ë³€ê²½ ì‚¬ìœ ì™€ ê²°ì • ë°°ê²½ ì„¤ëª…
3. ë³€ê²½ ì „í›„ ë¹„êµê°€ ê°€ëŠ¥í•˜ë„ë¡ ì •ë¦¬
4. ê´€ë ¨ ê²°ì¬ ë¬¸ì„œë‚˜ íšŒì˜ë¡ ì°¸ì¡° ì•ˆë‚´
5. í–¥í›„ ì˜ˆì •ëœ ë³€ê²½ ì‚¬í•­ë„ í¬í•¨""",

            "process": """ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ ì „ë¬¸ ì¸ìˆ˜ì¸ê³„ ë‹´ë‹¹ìì…ë‹ˆë‹¤.

[í•µì‹¬ ì§€ì¹¨]
1. ì—…ë¬´ ì§„í–‰ ìˆœì„œë¥¼ ë‹¨ê³„ë³„ë¡œ ëª…í™•íˆ ì„¤ëª…
2. ê° ë‹¨ê³„ë³„ ë‹´ë‹¹ì, ì†Œìš” ì‹œê°„, í•„ìš” ì„œë¥˜ ì•ˆë‚´
3. ì£¼ì˜ì‚¬í•­ê³¼ ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ ì‚¬ë¡€ ê³µìœ 
4. ê´€ë ¨ ì‹œìŠ¤í…œì´ë‚˜ í”„ë¡œê·¸ë¨ ì‚¬ìš©ë²• í¬í•¨
5. ì—…ë¬´ ì¸ê³„ ì‹œ ë°˜ë“œì‹œ ì•Œì•„ì•¼ í•  ë…¸í•˜ìš° ì „ë‹¬""",

            "general": """ë‹¹ì‹ ì€ ê³µê³µê¸°ê´€ ì—…ë¬´ ì¸ìˆ˜ì¸ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[í•µì‹¬ ì§€ì¹¨]
1. í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€
2. ë¬¸ì„œì—ì„œ í™•ì¸ëœ ì •ë³´ë§Œ ì •í™•íˆ ì „ë‹¬
3. ê°€ë…ì„±ì„ ìœ„í•´ í‘œ, ëª©ë¡, ë‹¨ê³„ë³„ í˜•ì‹ í™œìš©
4. ê´€ë ¨ ë¬¸ì„œ ì¶œì²˜ë¥¼ ëª…ì‹œ
5. ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ í™•ì¸ë˜ì§€ ì•ŠìŒ" í‘œì‹œ"""
        }
    
    def setup(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("=" * 70)
        print("ğŸ›ï¸ ê³µê³µê¸°ê´€ ì¸ìˆ˜ì¸ê³„ RAG ì‹œìŠ¤í…œ v2")
        print("=" * 70)
        print(f"ğŸ“ ì„œë²„: {BASE_URL}")
        print(f"ğŸ’¾ DB ê²½ë¡œ: {CHROMA_DB_PATH}")
        print(f"ğŸ“ ë¬¸ì„œ ê²½ë¡œ: {DATA_DIR}")
        print()
        
        # ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
        print("[ì—°ê²° í…ŒìŠ¤íŠ¸] vLLM ì„œë²„ í™•ì¸ ì¤‘...", end="", flush=True)
        try:
            self.client.models.list()
            print(" âœ… ì—°ê²° ì„±ê³µ!")
        except Exception as e:
            print(f" âŒ ì‹¤íŒ¨!")
            print(f"ğŸ”´ ì˜¤ë¥˜: {e}")
            print("\nğŸ’¡ SSH í„°ë„ë§ì„ í™•ì¸í•˜ì„¸ìš”.")
            return False
        
        # ì„ë² ë”© ë° DB ì„¤ì •
        print("\n[1/4] í•œêµ­ì–´ ì„ë² ë”© ì—”ì§„ ë¡œë“œ ì¤‘...")
        ko_embedding = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="jhgan/ko-sroberta-multitask"
        )
        
        print("[2/4] ChromaDB ì´ˆê¸°í™” ì¤‘...")
        db_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
        self.collection = db_client.get_or_create_collection(
            "handover_docs",
            embedding_function=ko_embedding
        )
        
        # ë¬¸ì„œ ë¡œë“œ
        print("[3/4] ë¬¸ì„œ ë¡œë“œ ì¤‘...")
        self._load_documents()
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
        print("[4/4] í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        self.searcher = HybridSearcher(self.collection)
        
        print("\nâœ… ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
        return True
    
    def _load_documents(self):
        """ë¬¸ì„œ ë¡œë“œ ë° ìƒ‰ì¸"""
        from local_rag import (
            read_pdf, read_docx, read_excel, read_hwp, read_hwpx, 
            read_text_file, split_text
        )
        
        loaders = {
            ".txt": read_text_file,
            ".md": read_text_file,
            ".pdf": read_pdf,
            ".docx": read_docx,
            ".xlsx": read_excel,
            ".xls": read_excel,
            ".hwp": read_hwp,
            ".hwpx": read_hwpx
        }
        
        if not os.path.exists(DATA_DIR):
            os.makedirs(DATA_DIR)
            print(f"   ğŸ“ '{DATA_DIR}' í´ë” ìƒì„±ë¨")
            return
        
        all_files = glob.glob(os.path.join(DATA_DIR, "*.*"))
        docs, metas, ids = [], [], []
        
        for file_path in all_files:
            ext = os.path.splitext(file_path)[1].lower()
            if ext not in loaders:
                continue
            
            try:
                content = loaders[ext](file_path)
                if content and len(content.strip()) > 10:
                    # ì²­í¬ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ë” ë§ì€ ê²°ê³¼ ê²€ìƒ‰ ê°€ëŠ¥
                    chunks = split_text(content, chunk_size=1500, overlap=300)
                    
                    for j, chunk in enumerate(chunks):
                        docs.append(chunk)
                        metas.append({
                            "source": os.path.basename(file_path),
                            "type": ext,
                            "chunk": j,
                            "doc_type": self._infer_doc_type(file_path, chunk)
                        })
                        ids.append(f"{os.path.basename(file_path)}_chunk_{j}")
                    
                    print(f"   âœ… {os.path.basename(file_path)} â†’ {len(chunks)}ê°œ ì²­í¬")
            except Exception as e:
                print(f"   âŒ {os.path.basename(file_path)}: {e}")
        
        if docs:
            self.collection.upsert(documents=docs, metadatas=metas, ids=ids)
            print(f"   ğŸ“š ì´ {len(docs)}ê°œ ì²­í¬ ìƒ‰ì¸ ì™„ë£Œ")
    
    def _infer_doc_type(self, file_path: str, content: str) -> str:
        """ë¬¸ì„œ ìœ í˜• ì¶”ë¡ """
        filename = os.path.basename(file_path).lower()
        content_lower = content.lower()
        
        if any(kw in filename for kw in ["ì˜ˆì‚°", "ê²°ì‚°", "ì„¸ì¶œ", "ì„¸ì…"]):
            return "budget"
        elif any(kw in filename for kw in ["ê·œì •", "ì§€ì¹¨", "ë§¤ë‰´ì–¼"]):
            return "regulation"
        elif any(kw in filename for kw in ["ì¡°ì§", "ë¶„ì¥", "ë‹´ë‹¹"]):
            return "organization"
        elif "ì›" in content and any(c.isdigit() for c in content):
            return "budget"
        else:
            return "general"
    
    def ask(self, query: str) -> str:
        """ì§ˆë¬¸ì— ë‹µë³€"""
        
        # 1. ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
        query_type, confidence = QueryClassifier.classify(query)
        print(f"   ğŸ“‹ ì§ˆë¬¸ ìœ í˜•: {query_type} (ì‹ ë¢°ë„: {confidence:.1%})")
        
        # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        print("   ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¤‘...", end="", flush=True)
        
        # ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ ì¡°ì •
        if query_type == "budget":
            # ì˜ˆì‚° ì§ˆë¬¸ì€ í‚¤ì›Œë“œ ë§¤ì¹­ ì¤‘ìš” (ì²­í¬ê°€ ì‘ì•„ì„œ 5ê°œ ê°€ëŠ¥)
            results = self.searcher.search(query, n_results=5, 
                                          bm25_weight=0.5, vector_weight=0.5)
        else:
            # ì¼ë°˜ì ì¸ ê²½ìš° ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ìš°ì„ 
            results = self.searcher.search(query, n_results=5,
                                          bm25_weight=0.3, vector_weight=0.7)
        
        print(" ì™„ë£Œ!")
        
        # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = ""
        sources = set()
        for doc, meta in zip(results['documents'][0], results['metadatas'][0]):
            source = meta.get('source', 'unknown')
            doc_type = meta.get('doc_type', 'general')
            sources.add(source)
            context += f"[ğŸ“„ {source} | ìœ í˜•: {doc_type}]\n{doc}\n\n"
        
        print(f"   ğŸ“š ì°¸ê³  ë¬¸ì„œ: {len(results['documents'][0])}ê°œ")
        
        # 4. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        system_prompt = self.system_prompts.get(query_type, self.system_prompts["general"])
        
        # 5. LLM í˜¸ì¶œ
        print("   ğŸ¤– AI ë¶„ì„ ì¤‘:\n")
        
        user_prompt = f"""ì•„ë˜ ì¸ìˆ˜ì¸ê³„ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ìƒì„¸íˆ ë‹µë³€í•´ ì£¼ì„¸ìš”.

[ì°¸ê³  ë¬¸ì„œ]
{context}

[ì§ˆë¬¸]
{query}

[ë‹µë³€ í˜•ì‹]
- í•µì‹¬ ë‚´ìš©ì„ ë¨¼ì € ìš”ì•½
- ìƒì„¸ ë‚´ìš©ì€ í‘œë‚˜ ëª©ë¡ìœ¼ë¡œ ì •ë¦¬
- ê´€ë ¨ ê·œì •ì´ë‚˜ ê·¼ê±°ê°€ ìˆìœ¼ë©´ ì–¸ê¸‰
- ë§ˆì§€ë§‰ì— ì°¸ê³ í•œ ë¬¸ì„œëª… í‘œì‹œ"""

        try:
            stream = self.client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.0,
                stream=True
            )
            
            response = ""
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    print(content, end="", flush=True)
                    response += content
            
            print(f"\n\n   ğŸ“„ ì°¸ê³  íŒŒì¼: {', '.join(sources)}")
            return response
            
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜: {e}")
            return ""
    
    def run(self):
        """ëŒ€í™”í˜• ì‹¤í–‰"""
        print("\n" + "=" * 70)
        print("ğŸ’¡ ì¸ìˆ˜ì¸ê³„ ì§ˆë¬¸ ì˜ˆì‹œ:")
        print("   - 2026ë…„ ì˜ˆì‚° ì„¸ë¶€ í•­ëª©ì„ í‘œë¡œ ì •ë¦¬í•´ì¤˜")
        print("   - ì¶œì¥ë¹„ ì •ì‚° ì ˆì°¨ë¥¼ ë‹¨ê³„ë³„ë¡œ ì•Œë ¤ì¤˜")
        print("   - ë‹´ë‹¹ ì—…ë¬´ ë¶„ì¥ì€ ì–´ë–»ê²Œ ë˜ì–´ ìˆì–´?")
        print("   - ìµœê·¼ ê·œì • ê°œì • ì´ë ¥ì„ ì•Œë ¤ì¤˜")
        print("=" * 70)
        print("(ì¢…ë£Œ: quit)")
        print()
        
        while True:
            query = input("\nì§ˆë¬¸: ")
            if query.lower() in ["quit", "exit", "ì¢…ë£Œ"]:
                print("ğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not query.strip():
                continue
            
            self.ask(query)


def main():
    # BM25 ì˜ì¡´ì„± í™•ì¸
    try:
        from rank_bm25 import BM25Okapi
    except ImportError:
        print("âš ï¸ rank_bm25 ì„¤ì¹˜ í•„ìš”: pip install rank-bm25")
        return
    
    rag = HandoverRAG()
    if rag.setup():
        rag.run()


if __name__ == "__main__":
    main()
